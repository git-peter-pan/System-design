Scenario: case/interface
Necessary: constrain/hypothesis
step1:ask daily active users
step2:predict 
user
	daily_active_users
	average conccurent users = daily_active_users/daily_senconds*average_online_time
这个指标不对，系统能力取决于高峰时间能力
	peak_users = average conccurent users  * 6
//要预测未来，可能三个月以后上市，
max_peak_users in 3 months = peak_users*2 

估算流量：
Traffic
	traffic per user = 3 mbps(video)
	max_peak_traffic = max_peak_users*traffic_per_second = 1,250,000*3mbps=3.75 Tb/s(>30% of US traffic)

Memory
	memory_per_user = 10kb
	Max_daily_memory = 5,000,000*2*10(3 months later) = 100GB

Storage
	total movie = 14,000(movies)
	movie_storage = total_movie*average_movie_size = 14,000*50G(different resolution)= 700 TB

Application:service/algorithm
	模块设计

kilobit:data

	user service: mysql,
	channel service:mongoDB
	movie: file
Evolve: 
	step1: analyze
		with
			better:constrains
			broder:new cases
			deeper:details
		from the views of
			performance
			scalability
			robustness
	step2: goback by evolving accordingly

SNAKE:
	scenario
	neccessary
	application
	kilobit
	Evolve




WEB CRAWLER && TINY URL
design crawler
design thread-safe consumer and producer(Amazon) CAN PRACTISE URSELF
design a tinyurl CAN PRACTISE URSELF

interview : let's implement on singers

based on data: web pages--information collection --database -- information retrieval--(rank, search, recommend)
rank, search and recommand can combine into rank
if rank and recommand use different datasets, rank based on clicks, recommand based on social graph, you'd better
seperate them.

crawl:(python)
url = 'http://xxx/xxx/xxx.shtml'; 
request = urllib2.Request(url); //write a letter
response = urllib2.urlopen(request); //send the letter and get the reply
page = response.read(); // read the reply
//save the source file
webFile = open('webPage.html', 'wb')
webFile.write(page); 

interview: what is the process druing crawler

crawler: socket() -- > connect() -- > read() write() -- > close()
web server: socket() ->bind() -- >listen() -> accept() -> read /write()
similar like call center
http connection
syn - syn-ack - ack 1st

http application layer
socket abstract layer for under layers
TCP /UDP transportation layer
IP network layer
Hardware interface link layer

What is HTML
html uses a tree to represent a page
svg: scalable vector graphics(SVG)

INTERVIEW:crawl all the news of a website:
crawl all the news page
identify the list page
http://yue.ifen.com/news/list_0/0.shtml
list_0 .... can increase maybe
0.shtml can increase maybe 
regex:

ans:
import re;
 pattern = re.compile("<a href="http://yue.ifeng.com/news/detail_(.*?)"target="_blank">(.*?)</a>', re.S);
.: any character
*: zero or more 
?: zero or one
items = re.findall(patter, page);

architecture(v1)
List crawler -> links of news -> news crawler -> pages of news

Interview: crawl more page
architecture(v2)
ifen.com-                         - many ifeng.com(new crawler)
sina.com-scheduler(links of news) - many sina.com -- page of news
163.com-                          - many 163.com
Interview: drawback of this architecture
news cralwer can be used repeatly.

architecture:
many crawler 
scheduler(two strategy: list, news)
task table: task id, priority(list > url), type(page_ifen, list_163), state(done, working, new), link, 
available time(), endTime

INTERVIEWER: design a scheduler? producer and consumer model
Solution with sleep
while(true)
	lock(tasktable);
	while tasktable.find("stat == new") == null
		release(tasktable);
		sleep(1s);
	end while
	lock(tasktable);
	task = tasktable.findone("state == new");
	task.state = "working";
	release(tasktable);

	page=crawl(task.url);

	if task.type == list;
		lock(tasktable);
		for newtask in page
		 	tasktable.add(newTask);
		 	task.state = "done";
		 release(tasktable);
	else
		lock(tasktable);
		pageTable.add(page);
		release(tasktable);
end while
INTERVIEW: SOMETHING WRONG WITH THE CODE
state in else wasn't set up
lock(tasktable);
task.state = "done";
release(tasktable);

INTERVIWER: DESIGN SCHEDULER WITH CONDITIONAL VARIABLE(ask frequently)
modify:
while( tasktable.find(state == new))
	cond_wait.add(cond, tasktable)
	...
tasktable.add(newtask);
con_signal(cond);// after crawler is empty

conditional variable
cond_wait(cond, mutex)
 lock(cond.threadWaitList);
 cond.threadWaitList.add(this.thread);
 release(cond.threaWaitList);

 relaese(mutex);
 block(this.thread);
 lock(mutex);

 cond_signal(cond)
 	lock(cond.threadWaitList);
 	if(cond.threadWaitlist.size() > 0) 
 		thread = cond.threadwaitlist.pop();
 		wakeup(thread);
 	relaese(cond.threadwaitlist);

 Interview: implement with semaphone
 see the ppt

 INTERVIEW: DESIGN THE FASTEST consumer and producer
 disruptor(bonus);

 interview: find the duplicate 
 find the longest sentence in two pages and compare
 what if minor different
 find the longest substring.

 INTERVIEW : ADVAN conditional variable  vs. sleep
 latency sleep(1s);
 thread wake up and sleep frequently.

 exPOnential latency
 sleep 10ms, 100ms, 1s

 INTERVIEW: DISTRIBUTE CRAWLERS IN MULTIPLE MACHINES( distributed crawlers);
 diagram:ppt
 INTERVIEW: DRAWBACK
 TOO MANY CONNECTORS
 SENDER AND RECEIVER
 INTERVIEW: IS THAT GOOD?
 CONNECTION BECOME MORE. BUT NOT THE PROBLEM.
 CAN USE LESS MODULE, REUSE THE CONNECTOR. SIMPLER ARCHITECTURE.
 need 2 semaphone
 SOLUTION WITH DATABASE

 tiny url: start from twitter, only can tweet 140 characters
 design in microcosmic doesn't need to strictly obey the SNAKE

 API: 
 long to short 
 short to long
 statistics

 ALG:
  long to short
  data structure:90% use hash(wrong, not neccesary)

  brute force: count++ every time, jz.com/$count
  become too long after one year

  necessary
  daily active users
  1m
  insert:
  perday 1m *1%(function usage)*10(function frequency)=100k
  per year 100k * 265 = 36.5m;
  persecond 100k/86400 = 1.2 < 100qps, one machine can handle
  lookup
  per day: 1m * 100%(function usage) * 3(function frequency) = 3m;
  per second 3m/86400 = 35; peak = 35* 2 * 5 

  algorithm:
  2 maps/ 2 tables
  long to short 
  short to long

  generateShorURL()
  	return String(mLongToShort.size());

  may conflict

  INTERVIEW : how to reduce the size of map
  Yearly URL 36.5m
  usable characters[0-9] = 10;
  encoding length = log10(36.5m) = 7.6 = 8;
  example goo.gl/36500000


  improve
  usable characters
  [0-9a-zA-Z]: easy to type
  log62(36.5m) = 4.2
  example: goo.gl/2t9jG

  String ConvertTo62(int number) 
  	char Encode[62] = {'0',....,'9','a',...,'z','A',...,'Z'};
  	String res = "";
  	while(number)
  		res = Encode[number%62] + res;
  		number /= 62;
  	return res;

 Kilobit
 average size of longURL = 100bytes
 average size of shortURL = 4bytes(int)
 state = 4 byte(expired , not availabe)
 daily new URL = 100k * 100 = 10.8mb
 yearly new URL = 10.8MB*365 = 4GB < 1TB can handle by memory
 database: mysql or NoSQL

 INTERVIEW : URL POLLUTION(BAD POLLUTION)
 input same ip more than 5 times, need to identify security code

 FOLLOW UP
 HOW TO SUPPORT RANDOM
 random(0, range);
 How to avoid conflicting 
 try again, low probability

 How to implement time-limited service?
 exipire/state
 how to cache
 pre-load & wait limit
 replacement

 HOW TO SUPPORT ANALYSIS
 A LOG:
 date:
 time:
 referer
 ip
 country
 to
 browser
 platform

 bucket 
 last two hour buckets
 last day buckets
 last week bukcets: doesn't need to store data, because is caculated in last month
 last month buckets
 all time buckets

 use log to update all the bucket table
o(4)
 web crawler: less in 1 min;

  	
